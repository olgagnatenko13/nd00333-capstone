{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423888013
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Webservice\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib \n",
    "import requests\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "#### Dataset description\n",
    "The dataset contains data about 1,470 employees - their demographic, personal and professional characteristics, as well as information about employee attrition. \"Attrition\" is the target column. \n",
    "\n",
    "The dataset is retrieved from https://www.kaggle.com/alhassanabdelglil/classification \n",
    "\n",
    "To avoid access issues, I have uploaded an unpacked copy of the dataset into own Github account, and load the dataset to AzureML from this copy.\n",
    "\n",
    "#### Task\n",
    "The purpose of the model is to assess whether an employee is experiencing attrition or not, based on employee's personal and professional characteristics. This task is a classification task.\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598423890461
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'og-azureml-capstone'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create or retrieve a compute cluster\n",
    "cluster_name = list(ws.compute_targets.keys())[0]\n",
    "if not(cluster_name):\n",
    "    cluster_name = 'capstone-cluster'\n",
    "    try:\n",
    "        cluster = ComputeTarget(workspace = ws, name = cluster_name)\n",
    "        print(\"Cluster already exists, start using it\")\n",
    "    except ComputeTargetException:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", max_nodes = 4)\n",
    "        cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    cluster.wait_for_completion(show_output = True)\n",
    "else:\n",
    "    cluster = ComputeInstance(workspace = ws, name = cluster_name)\n",
    "    print(\"Cluster already exists:\", cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload dataset to the workspace\n",
    "data_path = \"https://raw.githubusercontent.com/olgagnatenko13/nd00333-capstone/master/dataset/Dataset_for_Classification.csv\"\n",
    "found = False\n",
    "key = \"attrition-analysis\"\n",
    "description_text = \"Employee attrition data\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "    found = True\n",
    "    dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "    # Create AML Dataset and register it into Workspace\n",
    "    dataset = Dataset.Tabular.from_delimited_files(data_path)        \n",
    "      \n",
    "    dataset = dataset.register(workspace=ws, name=key, description=description_text)\n",
    "\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into test and train \n",
    "test_size = 0.25\n",
    "random_state = 7\n",
    "\n",
    "ready_ds = pd.concat([x, y], axis=1, sort = False)\n",
    "ds_train, ds_test = train_test_split(ready_ds, test_size = test_size, random_state = random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save split datasets \n",
    "data_folder='./data'\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "data_path_train = os.path.join(data_folder, \"ds_train.csv\")\n",
    "data_path_test = os.path.join(data_folder, \"ds_test.csv\")\n",
    "\n",
    "ds_train.to_csv(data_path_train, index = False)\n",
    "ds_test.to_csv(data_path_test, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load split datasets\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir = data_folder, target_path = \"data\", overwrite=True, show_progress=True)\n",
    "tabular_ds_train = TabularDatasetFactory.from_delimited_files(path = datastore.path(\"data/ds_train.csv\"))\n",
    "tabular_ds_test = TabularDatasetFactory.from_delimited_files(path = datastore.path(\"data/ds_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and configuration you used below.\n",
    "\n",
    "- experiment_timeout_minutes=20: to avoid virtual machine timeout, we limit AutoML experiment time \n",
    "- task = \"classification\": the selected question is a binary classification task \n",
    "- primary metric - accuracy, as in hyperparameter experiment, for compatibility purposes, and due to the fact that correct identification of positives and negatives is equally important \n",
    "- training_data = tabular_ds_train: we train the model on the \"train\" part of the dataset\n",
    "- label_column_name = \"y\": the data about employee attrition are located in column \"y\"\n",
    "- n_cross_validations = 3: we specifically indicate to use cross-validation approach instead of default train-test split, and select three cross-validation folds\n",
    "- debug_log = 'automl_errors.log': place automl logs into a file for future analysis \n",
    "- compute_target = cluster_name: indicate the compute to run the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598429217746
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "\n",
    "automl_settings = (\n",
    "    experiment_timeout_minutes = 20, \n",
    "    task = \"classification\",\n",
    "    primary_metric = \"accuracy\",\n",
    "    training_data = tabular_ds_train,\n",
    "    label_column_name = \"y\",\n",
    "    n_cross_validations = 3,\n",
    "    debug_log = 'automl_errors.log',\n",
    "    compute_target = cluster_name\n",
    ")\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(automl_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Submit your experiment\n",
    "remote_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "**Top three models**\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Show Run Details\n",
    "RunDetails(remote_run).show()\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get best model and its details\n",
    "output_folder='./outputs'\n",
    "\n",
    "best_automl_run, best_automl_model = remote_run.get_output()\n",
    "run_details = best_automl_run.get_details()\n",
    "\n",
    "model_details = {\n",
    "    'RunID': [run_details['runId']],\n",
    "    'Iteration': [run_details['properties']['iteration']],\n",
    "    'Primary metric': [run_details['properties']['primary_metric']],\n",
    "    'Score': [run_details['properties']['score']],\n",
    "    'Algorithm and hyperparameters': [best_automl_model.steps]\n",
    "}\n",
    "\n",
    "print(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all steps of the model \n",
    "def print_model(model, prefix=\"\"):\n",
    "    for step in model.steps:\n",
    "        print(prefix + step[0])\n",
    "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
    "            pprint({'estimators': list(e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
    "            print()\n",
    "            for estimator in step[1].estimators:\n",
    "                print_model(estimator[1], estimator[0]+ ' - ')\n",
    "        elif hasattr(step[1], '_base_learners') and hasattr(step[1], '_meta_learner'):\n",
    "            print(\"\\nMeta Learner\")\n",
    "            pprint(step[1]._meta_learner)\n",
    "            print()\n",
    "            for estimator in step[1]._base_learners:\n",
    "                print_model(estimator[1], estimator[0]+ ' - ')\n",
    "        else:\n",
    "            pprint(step[1].get_params())\n",
    "            print()\n",
    "\n",
    "print_model(best_automl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "model_file_name = 'automl_best_model.pkl'\n",
    "model_full_path = os.path.join(output_folder, model_file_name)\n",
    "joblib.dump(value = best_automl_model, filename = model_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best model to test dataset, and compute accuracy to compare with Hyperdrive model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = TabularDatasetFactory.from_delimited_files(path = datastore.path(\"data/ds_test.csv\"))\n",
    "y_test = y_test.keep_columns(\"y\").to_pandas_dataframe()\n",
    "tabular_ds_test = tabular_ds_test.drop_columns(\"y\").to_pandas_dataframe()\n",
    "y_predict = best_automl_model.predict(tabular_ds_test)\n",
    "automl_accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"Automl accuracy\", automl_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Register model\n",
    "model = Model.register(\n",
    "    workspace = ws,\n",
    "    model_path = model_full_path,\n",
    "    model_name = 'model_full_path',\n",
    "    description = 'AutoML model predicting employee attrition'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Aci config and inference config\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1,\n",
    "    memory_gb = 1,\n",
    "    description = 'AutoML model predicting employee attrition'\n",
    ")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script = \"score.py\", environment = environment)\n",
    "\n",
    "deployed_model_name = 'attrition-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model as a web service\n",
    "service = Model.deploy(\n",
    "    workspace = ws,\n",
    "    name = deployed_model_name,\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = aci_config,\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "url = service.scoring_uri\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_employee = ds_train.iloc[0].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Send a request to the web service\n",
    "headers = {'Content-Type':'application/json'}\n",
    "r = requests.post(url, data = {'data': [test_employee]} , headers = headers)\n",
    "print(r.status_code)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# print logs \n",
    "service = Webservice(ws, deployed_model_name)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete web service \n",
    "service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
