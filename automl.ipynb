{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automated ML\n",
    "\n",
    "TODO: Import Dependencies. In the cell below, import all the dependencies that you will need to complete the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "gather": {
     "logged": 1618781027348
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Experiment, Webservice\n",
    "from azureml.core.dataset import Dataset\n",
    "from azureml.core.environment import Environment\n",
    "from azureml.core.model import Model, InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "from azureml.core.compute import ComputeTarget, ComputeInstance\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "from azureml.train.automl import AutoMLConfig\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "from azureml.data.dataset_factory import TabularDatasetFactory\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import joblib \n",
    "import requests\n",
    "import os\n",
    "import pandas as pd \n",
    "from pprint import pprint\n",
    "from training.train import clean_data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Overview\n",
    "TODO: In this markdown cell, give an overview of the dataset you are using. Also mention the task you will be performing.\n",
    "\n",
    "#### Dataset description\n",
    "The dataset is retrieved from https://www.kaggle.com/alhassanabdelglil/classification \n",
    "Employee attrition is a significant issue that impacts both the individual's quality of life, and work performance. Detecting individuals who are close to attrition, or are already experiencing it, can be used to prevent deterioration of work performance and life quality.\n",
    "\n",
    "The dataset contains data about 1,470 employees - their demographic, personal and professional characteristics, workplace characterisics, as well as information about employee attrition. \"Attrition\" is the target column used for train and test purposes. \n",
    "\n",
    "To avoid access issues, I have uploaded an unpacked copy of the dataset into own Github account, and loaded the dataset to AzureML from this copy.\n",
    "\n",
    "#### Task\n",
    "The purpose of the model is to assess whether an employee is experiencing attrition or not, based on employee's personal and professional characteristics. This task is a classification task.\n",
    "\n",
    "TODO: Get data. In the cell below, write code to access the data you will be using in this project. Remember that the dataset needs to be external."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "gather": {
     "logged": 1618780958897
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "ws = Workspace.from_config()\n",
    "\n",
    "# choose a name for experiment\n",
    "experiment_name = 'og-azureml-capstone'\n",
    "experiment=Experiment(ws, experiment_name)\n",
    "run = experiment.start_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "gather": {
     "logged": 1618780962135
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster already exists: notebook143078\n"
     ]
    }
   ],
   "source": [
    "# Create or retrieve a compute cluster\n",
    "cluster_name = list(ws.compute_targets.keys())[0]\n",
    "if not(cluster_name):\n",
    "    cluster_name = 'capstone-cluster'\n",
    "    try:\n",
    "        cluster = ComputeTarget(workspace = ws, name = cluster_name)\n",
    "        print(\"Cluster already exists, start using it\")\n",
    "    except ComputeTargetException:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D2_V2\", max_nodes = 4)\n",
    "        cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "\n",
    "    cluster.wait_for_completion(show_output = True)\n",
    "else:\n",
    "    cluster = ComputeInstance(workspace = ws, name = cluster_name)\n",
    "    print(\"Cluster already exists:\", cluster_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "gather": {
     "logged": 1618780966294
    }
   },
   "outputs": [],
   "source": [
    "# Upload dataset to the workspace\n",
    "data_path = \"https://raw.githubusercontent.com/olgagnatenko13/nd00333-capstone/master/dataset/Dataset_for_Classification.csv\"\n",
    "found = False\n",
    "key = \"attrition-analysis\"\n",
    "description_text = \"Employee attrition data\"\n",
    "\n",
    "if key in ws.datasets.keys(): \n",
    "    found = True\n",
    "    dataset = ws.datasets[key] \n",
    "\n",
    "if not found:\n",
    "    # Create AML Dataset and register it into Workspace\n",
    "    dataset = Dataset.Tabular.from_delimited_files(data_path)        \n",
    "      \n",
    "    dataset = dataset.register(workspace=ws, name=key, description=description_text)\n",
    "\n",
    "df = dataset.to_pandas_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "gather": {
     "logged": 1618781051032
    }
   },
   "outputs": [],
   "source": [
    "# Clean data, split the dataset into test and train \n",
    "x, y = clean_data(dataset)\n",
    "\n",
    "test_size = 0.25\n",
    "random_state = 7\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = test_size, random_state = random_state, stratify = y)\n",
    "\n",
    "ds_train = pd.concat([x_train, y_train], axis=1, sort = False)\n",
    "ds_test = pd.concat([x_test, y_test], axis=1, sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "gather": {
     "logged": 1618779091869
    }
   },
   "outputs": [],
   "source": [
    "# Save split datasets \n",
    "data_folder='./data'\n",
    "os.makedirs(data_folder, exist_ok=True)\n",
    "data_path_train = os.path.join(data_folder, \"ds_train.csv\")\n",
    "data_path_test = os.path.join(data_folder, \"ds_test.csv\")\n",
    "\n",
    "ds_train.to_csv(data_path_train, index = False)\n",
    "ds_test.to_csv(data_path_test, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "gather": {
     "logged": 1618779242849
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploading an estimated of 2 files\n",
      "Uploading ./data/ds_test.csv\n",
      "Uploaded ./data/ds_test.csv, 1 files out of an estimated total of 2\n",
      "Uploading ./data/ds_train.csv\n",
      "Uploaded ./data/ds_train.csv, 2 files out of an estimated total of 2\n",
      "Uploaded 2 files\n"
     ]
    }
   ],
   "source": [
    "# load split datasets\n",
    "datastore = ws.get_default_datastore()\n",
    "datastore.upload(src_dir = data_folder, target_path = \"data\", overwrite=True, show_progress=True)\n",
    "tabular_ds_train = TabularDatasetFactory.from_delimited_files(path = datastore.path(\"data/ds_train.csv\"))\n",
    "tabular_ds_test = TabularDatasetFactory.from_delimited_files(path = datastore.path(\"data/ds_test.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML Configuration\n",
    "\n",
    "TODO: Explain why you chose the automl settings and configuration you used below.\n",
    "\n",
    "### Automl settings\n",
    "- experiment_timeout_minutes = 20: to avoid virtual machine timeout, we limit AutoML experiment time \n",
    "- max_concurrent_iterations = 5: we limit the number of parallel iterations to optimize resource use \n",
    "- task = \"classification\": the selected problem is a binary classification task \n",
    "- primary metric - accuracy (as in the hyperparameter experiment) for compatibility purposes, and due to the fact that correct identification of positives and negatives is equally important \n",
    "- label_column_name = \"Attrition\": the data about employee attrition are located in column \"Attrition\"\n",
    "- n_cross_validations = 3: we specifically indicate to use cross-validation approach instead of default train-test split, and select three cross-validation folds\n",
    "- debug_log = 'automl_errors.log': place automl logs into a file for future analysis \n",
    "- featurization = \"auto\": allow AutoML to perform featurization based on the task type \n",
    "- enable_early_stopping: True: apply early termination if the score is not improving in the long-term perspective - this option is selected to make the run faster \n",
    "\n",
    "### Configuration\n",
    "- training_data = tabular_ds_train: we train the model on the \"train\" part of the dataset\n",
    "- compute_target = cluster_name: indicate the compute to run the experiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "gather": {
     "logged": 1618780227795
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Put your automl settings here\n",
    "\n",
    "automl_settings = {\n",
    "    \"experiment_timeout_minutes\": 20,\n",
    "    \"max_concurrent_iterations\": 5,\n",
    "    \"task\": \"classification\",\n",
    "    \"primary_metric\" : \"accuracy\",\n",
    "    \"label_column_name\": \"Attrition\",\n",
    "    \"n_cross_validations\": 3,\n",
    "    \"debug_log\": \"automl_errors.log\",\n",
    "    \"featurization\": \"auto\",\n",
    "    \"enable_early_stopping\": True\n",
    "}\n",
    "\n",
    "# TODO: Put your automl config here\n",
    "automl_config = AutoMLConfig(\n",
    "    compute_target = cluster_name,\n",
    "    training_data = tabular_ds_train,  \n",
    "    **automl_settings\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "gather": {
     "logged": 1598431107951
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting remote run.\n"
     ]
    },
    {
     "ename": "ValidationException",
     "evalue": "ValidationException:\n\tMessage: Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\n    \"additional_properties\": {\n        \"debugInfo\": null\n    },\n    \"code\": \"UserError\",\n    \"severity\": 2,\n    \"message\": \"For a classification task, the y input needs at least two classes of labels.\",\n    \"message_format\": \"For a classification task, the y input needs at least two classes of labels.\",\n    \"message_parameters\": {},\n    \"reference_code\": null,\n    \"details_uri\": null,\n    \"target\": \"training_data\",\n    \"details\": [\n        {\n            \"additional_properties\": {\n                \"debugInfo\": null\n            },\n            \"code\": null,\n            \"severity\": null,\n            \"message\": \"null\",\n            \"message_format\": null,\n            \"message_parameters\": {},\n            \"reference_code\": null,\n            \"details_uri\": null,\n            \"target\": null,\n            \"details\": [],\n            \"inner_error\": null\n        }\n    ],\n    \"inner_error\": {\n        \"additional_properties\": {},\n        \"code\": \"BadData\",\n        \"inner_error\": {\n            \"additional_properties\": {},\n            \"code\": \"InvalidData\",\n            \"inner_error\": {\n                \"additional_properties\": {},\n                \"code\": \"SingleClass\",\n                \"inner_error\": null\n            }\n        }\n    }\n}]\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\\n    \\\"additional_properties\\\": {\\n        \\\"debugInfo\\\": null\\n    },\\n    \\\"code\\\": \\\"UserError\\\",\\n    \\\"severity\\\": 2,\\n    \\\"message\\\": \\\"For a classification task, the y input needs at least two classes of labels.\\\",\\n    \\\"message_format\\\": \\\"For a classification task, the y input needs at least two classes of labels.\\\",\\n    \\\"message_parameters\\\": {},\\n    \\\"reference_code\\\": null,\\n    \\\"details_uri\\\": null,\\n    \\\"target\\\": \\\"training_data\\\",\\n    \\\"details\\\": [\\n        {\\n            \\\"additional_properties\\\": {\\n                \\\"debugInfo\\\": null\\n            },\\n            \\\"code\\\": null,\\n            \\\"severity\\\": null,\\n            \\\"message\\\": \\\"null\\\",\\n            \\\"message_format\\\": null,\\n            \\\"message_parameters\\\": {},\\n            \\\"reference_code\\\": null,\\n            \\\"details_uri\\\": null,\\n            \\\"target\\\": null,\\n            \\\"details\\\": [],\\n            \\\"inner_error\\\": null\\n        }\\n    ],\\n    \\\"inner_error\\\": {\\n        \\\"additional_properties\\\": {},\\n        \\\"code\\\": \\\"BadData\\\",\\n        \\\"inner_error\\\": {\\n            \\\"additional_properties\\\": {},\\n            \\\"code\\\": \\\"InvalidData\\\",\\n            \\\"inner_error\\\": {\\n                \\\"additional_properties\\\": {},\\n                \\\"code\\\": \\\"SingleClass\\\",\\n                \\\"inner_error\\\": null\\n            }\\n        }\\n    }\\n}]\",\n        \"inner_error\": {\n            \"code\": \"ExecutionFailure\"\n        }\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValidationException\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-2dd33d13fc7d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# TODO: Submit your experiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mremote_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mautoml_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/core/experiment.py\u001b[0m in \u001b[0;36msubmit\u001b[0;34m(self, config, tags, **kwargs)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0msubmit_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_experiment_submit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"submit config {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             \u001b[0mrun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msubmit_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtags\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0mrun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_tags\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\u001b[0m in \u001b[0;36m_automl_static_submit\u001b[0;34m(automl_config_object, workspace, experiment_name, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0mcompute_target\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mparent_run_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m             show_output)\n\u001b[0m\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0mautoml_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_properties\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mglobal_tracking_info_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\u001b[0m in \u001b[0;36m_start_execution\u001b[0;34m(experiment, settings_obj, fit_params, run_config, compute_target, parent_run_id, show_output)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msettings_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscenario\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mScenarios\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NON_PROD\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mvalidate_non_prod_env_exists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mautoml_run\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_default_execution\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msettings_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mautoml_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/automlconfig.py\u001b[0m in \u001b[0;36m_default_execution\u001b[0;34m(experiment, settings_obj, fit_params, legacy_local, show_output, parent_run_id)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0mexperiment_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconsole_writer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshow_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperimentDriver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m     \u001b[0mupdated_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_parent_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0mstart_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_combine_start_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupdated_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mstart_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/_experiment_drivers/experiment_driver.py\u001b[0m in \u001b[0;36mcreate_parent_run\u001b[0;34m(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m             \u001b[0m_script_run\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0mparent_run_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m             kwargs)\n\u001b[0m\u001b[1;32m    222\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_run_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/_experiment_drivers/remote_experiment_launcher.py\u001b[0m in \u001b[0;36mcreate_parent_run\u001b[0;34m(self, run_configuration, compute_target, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, existing_run, training_data, validation_data, test_data, _script_run, parent_run_id, kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mrun_configuration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m             \u001b[0msample_weight_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv_splits_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_splits_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m             training_data=training_data, validation_data=validation_data, test_data=test_data)\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_run\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py\u001b[0m in \u001b[0;36mcreate_remote_parent_run\u001b[0;34m(experiment_state, run_config, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, training_data, validation_data, test_data)\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0msample_weight_valid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight_valid\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0mcv_splits_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv_splits_indices\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mtest_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m     )\n\u001b[1;32m    379\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py\u001b[0m in \u001b[0;36mcreate_and_validate_parent_run_dto\u001b[0;34m(experiment_state, target, training_data, validation_data, X, y, sample_weight, X_valid, y_valid, sample_weight_valid, cv_splits_indices, parent_run_id, test_data)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mparent_run_dto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_parent_run_dto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataprep_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_run_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mvalidate_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexperiment_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent_run_dto\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mparent_run_dto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/azureml/train/automl/_experiment_drivers/driver_utilities.py\u001b[0m in \u001b[0;36mvalidate_input\u001b[0;34m(experiment_state, parent_run_dto)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Validation error(s): {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetails\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         raise ValidationException._with_error(AzureMLError.create(\n\u001b[0;32m--> 157\u001b[0;31m             ExecutionFailure, operation_name=\"data/settings validation\", error_details=msg)\n\u001b[0m\u001b[1;32m    158\u001b[0m         )\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValidationException\u001b[0m: ValidationException:\n\tMessage: Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\n    \"additional_properties\": {\n        \"debugInfo\": null\n    },\n    \"code\": \"UserError\",\n    \"severity\": 2,\n    \"message\": \"For a classification task, the y input needs at least two classes of labels.\",\n    \"message_format\": \"For a classification task, the y input needs at least two classes of labels.\",\n    \"message_parameters\": {},\n    \"reference_code\": null,\n    \"details_uri\": null,\n    \"target\": \"training_data\",\n    \"details\": [\n        {\n            \"additional_properties\": {\n                \"debugInfo\": null\n            },\n            \"code\": null,\n            \"severity\": null,\n            \"message\": \"null\",\n            \"message_format\": null,\n            \"message_parameters\": {},\n            \"reference_code\": null,\n            \"details_uri\": null,\n            \"target\": null,\n            \"details\": [],\n            \"inner_error\": null\n        }\n    ],\n    \"inner_error\": {\n        \"additional_properties\": {},\n        \"code\": \"BadData\",\n        \"inner_error\": {\n            \"additional_properties\": {},\n            \"code\": \"InvalidData\",\n            \"inner_error\": {\n                \"additional_properties\": {},\n                \"code\": \"SingleClass\",\n                \"inner_error\": null\n            }\n        }\n    }\n}]\n\tInnerException: None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Failed to execute the requested operation: data/settings validation. Error details: Validation error(s): [{\\n    \\\"additional_properties\\\": {\\n        \\\"debugInfo\\\": null\\n    },\\n    \\\"code\\\": \\\"UserError\\\",\\n    \\\"severity\\\": 2,\\n    \\\"message\\\": \\\"For a classification task, the y input needs at least two classes of labels.\\\",\\n    \\\"message_format\\\": \\\"For a classification task, the y input needs at least two classes of labels.\\\",\\n    \\\"message_parameters\\\": {},\\n    \\\"reference_code\\\": null,\\n    \\\"details_uri\\\": null,\\n    \\\"target\\\": \\\"training_data\\\",\\n    \\\"details\\\": [\\n        {\\n            \\\"additional_properties\\\": {\\n                \\\"debugInfo\\\": null\\n            },\\n            \\\"code\\\": null,\\n            \\\"severity\\\": null,\\n            \\\"message\\\": \\\"null\\\",\\n            \\\"message_format\\\": null,\\n            \\\"message_parameters\\\": {},\\n            \\\"reference_code\\\": null,\\n            \\\"details_uri\\\": null,\\n            \\\"target\\\": null,\\n            \\\"details\\\": [],\\n            \\\"inner_error\\\": null\\n        }\\n    ],\\n    \\\"inner_error\\\": {\\n        \\\"additional_properties\\\": {},\\n        \\\"code\\\": \\\"BadData\\\",\\n        \\\"inner_error\\\": {\\n            \\\"additional_properties\\\": {},\\n            \\\"code\\\": \\\"InvalidData\\\",\\n            \\\"inner_error\\\": {\\n                \\\"additional_properties\\\": {},\\n                \\\"code\\\": \\\"SingleClass\\\",\\n                \\\"inner_error\\\": null\\n            }\\n        }\\n    }\\n}]\",\n        \"inner_error\": {\n            \"code\": \"ExecutionFailure\"\n        }\n    }\n}"
     ]
    }
   ],
   "source": [
    "# TODO: Submit your experiment\n",
    "remote_run = experiment.submit(automl_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Details\n",
    "\n",
    "OPTIONAL: Write about the different models trained and their performance. Why do you think some models did better than others?\n",
    "\n",
    "**Top three models**\n",
    "1. \n",
    "2. \n",
    "3. \n",
    "\n",
    "TODO: In the cell below, use the `RunDetails` widget to show the different experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "gather": {
     "logged": 1598431121770
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'remote_run' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c17ebdde2ca3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Show Run Details\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mRunDetails\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_run\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mremote_run\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_completion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'remote_run' is not defined"
     ]
    }
   ],
   "source": [
    "# Show Run Details\n",
    "RunDetails(remote_run).show()\n",
    "remote_run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best Model\n",
    "\n",
    "TODO: In the cell below, get the best model from the automl experiments and display all the properties of the model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431425670
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Get best model and its details\n",
    "output_folder='./outputs'\n",
    "\n",
    "best_automl_run, best_automl_model = remote_run.get_output()\n",
    "run_details = best_automl_run.get_details()\n",
    "\n",
    "model_details = {\n",
    "    'RunID': [run_details['runId']],\n",
    "    'Iteration': [run_details['properties']['iteration']],\n",
    "    'Primary metric': [run_details['properties']['primary_metric']],\n",
    "    'Score': [run_details['properties']['score']],\n",
    "    'Algorithm and hyperparameters': [best_automl_model.steps]\n",
    "}\n",
    "\n",
    "print(model_details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all steps of the model \n",
    "def print_model(model, prefix=\"\"):\n",
    "    for step in model.steps:\n",
    "        print(prefix + step[0])\n",
    "        if hasattr(step[1], 'estimators') and hasattr(step[1], 'weights'):\n",
    "            pprint({'estimators': list(e[0] for e in step[1].estimators), 'weights': step[1].weights})\n",
    "            print()\n",
    "            for estimator in step[1].estimators:\n",
    "                print_model(estimator[1], estimator[0]+ ' - ')\n",
    "        elif hasattr(step[1], '_base_learners') and hasattr(step[1], '_meta_learner'):\n",
    "            print(\"\\nMeta Learner\")\n",
    "            pprint(step[1]._meta_learner)\n",
    "            print()\n",
    "            for estimator in step[1]._base_learners:\n",
    "                print_model(estimator[1], estimator[0]+ ' - ')\n",
    "        else:\n",
    "            pprint(step[1].get_params())\n",
    "            print()\n",
    "\n",
    "print_model(best_automl_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431426111
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#TODO: Save the best model\n",
    "model_file_name = 'automl_best_model.pkl'\n",
    "model_full_path = os.path.join(output_folder, model_file_name)\n",
    "joblib.dump(value = best_automl_model, filename = model_full_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply best model to test dataset, and compute accuracy to compare with Hyperdrive model\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "y_test = TabularDatasetFactory.from_delimited_files(path = datastore.path(\"data/ds_test.csv\"))\n",
    "y_test = y_test.keep_columns(\"y\").to_pandas_dataframe()\n",
    "tabular_ds_test = tabular_ds_test.drop_columns(\"y\").to_pandas_dataframe()\n",
    "y_predict = best_automl_model.predict(tabular_ds_test)\n",
    "automl_accuracy = accuracy_score(y_test, y_predict)\n",
    "print(\"Automl accuracy\", automl_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Deployment\n",
    "\n",
    "Remember you have to deploy only one of the two models you trained.. Perform the steps in the rest of this notebook only if you wish to deploy this model.\n",
    "\n",
    "TODO: In the cell below, register the model, create an inference config and deploy the model as a web service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598431435189
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Register model\n",
    "model = Model.register(\n",
    "    workspace = ws,\n",
    "    model_path = model_full_path,\n",
    "    model_name = 'model_full_path',\n",
    "    description = 'AutoML model predicting employee attrition'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Aci config and inference config\n",
    "aci_config = AciWebservice.deploy_configuration(\n",
    "    cpu_cores = 1,\n",
    "    memory_gb = 1,\n",
    "    description = 'AutoML model predicting employee attrition'\n",
    ")\n",
    "\n",
    "inference_config = InferenceConfig(entry_script = \"score.py\", environment = environment)\n",
    "\n",
    "deployed_model_name = 'attrition-model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy the model as a web service\n",
    "service = Model.deploy(\n",
    "    workspace = ws,\n",
    "    name = deployed_model_name,\n",
    "    models = [model],\n",
    "    inference_config = inference_config,\n",
    "    deployment_config = aci_config,\n",
    "    overwrite = True\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output = True)\n",
    "url = service.scoring_uri\n",
    "print(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598431657736
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, send a request to the web service you deployed to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_employee = ds_train.iloc[0].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1598432707604
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Send a request to the web service\n",
    "headers = {'Content-Type':'application/json'}\n",
    "r = requests.post(url, data = {'data': [test_employee]} , headers = headers)\n",
    "print(r.status_code)\n",
    "print(r.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1598432765711
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "TODO: In the cell below, print the logs of the web service and delete the service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# print logs \n",
    "service = Webservice(ws, deployed_model_name)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete web service \n",
    "# service.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
